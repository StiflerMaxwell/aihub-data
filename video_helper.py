#!/usr/bin/env python3
"""
AIå·¥å…·å¯¼å…¥ç³»ç»Ÿ - çœŸå®è§†é¢‘URLè·å–åŠ©æ‰‹
ä¸“æ³¨äºä»AIå·¥å…·ç½‘ç«™æå–çœŸå®çš„æ¼”ç¤ºè§†é¢‘ã€äº§å“ä»‹ç»è§†é¢‘
"""

import requests
import re
import time
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse, parse_qs, urlunparse
from config import config
from logger import logger

class VideoHelper:
    """çœŸå®è§†é¢‘URLè·å–åŠ©æ‰‹"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        self.timeout = config.REQUEST_TIMEOUT
        
        # æ‰©å±•çš„è§†é¢‘å¹³å°URLæ¨¡å¼
        self.video_patterns = {
            'youtube': r'(?:https?:\/\/)?(?:www\.)?(?:youtube\.com\/(?:watch\?v=|embed\/|v\/)|youtu\.be\/)([a-zA-Z0-9_-]{11})',
            'vimeo': r'(?:https?:\/\/)?(?:www\.)?vimeo\.com\/(?:video\/)?(\d+)',
            'loom': r'(?:https?:\/\/)?(?:www\.)?loom\.com\/share\/([a-zA-Z0-9-]+)',
            'wistia': r'(?:https?:\/\/)?(?:[\w-]+\.)?wistia\.com\/(?:medias|embed)\/([a-zA-Z0-9]+)',
            'streamable': r'(?:https?:\/\/)?streamable\.com\/([a-zA-Z0-9]+)',
            'twitch': r'(?:https?:\/\/)?(?:www\.)?twitch\.tv\/videos\/(\d+)',
            'dailymotion': r'(?:https?:\/\/)?(?:www\.)?dailymotion\.com\/video\/([a-zA-Z0-9]+)',
            'direct_video': r'https?:\/\/[^\s]+\.(?:mp4|webm|ogg|mov|avi|m4v)(?:\?[^\s]*)?'
        }
        
        # å¸¸è§çš„è§†é¢‘ç›¸å…³å…³é”®è¯å’Œé€‰æ‹©å™¨
        self.video_keywords = [
            'demo', 'demonstration', 'tutorial', 'overview', 'introduction', 'walkthrough',
            'preview', 'showcase', 'how to', 'getting started', 'product tour',
            'æ¼”ç¤º', 'æ•™ç¨‹', 'ä»‹ç»', 'é¢„è§ˆ', 'å±•ç¤º', 'ä½¿ç”¨æ–¹æ³•'
        ]
        
        # è§†é¢‘å®¹å™¨çš„CSSé€‰æ‹©å™¨
        self.video_selectors = [
            'iframe[src*="youtube"]', 'iframe[src*="vimeo"]', 'iframe[src*="loom"]',
            'iframe[src*="wistia"]', 'video', 'embed[src*="youtube"]',
            '.video-container', '.demo-video', '.product-video', '.hero-video',
            '[data-video-id]', '[data-youtube-id]', '[data-vimeo-id]'
        ]
        
        # å·²éªŒè¯çš„çœŸå®AIå·¥å…·è§†é¢‘ï¼ˆå®šæœŸæ›´æ–°ï¼‰
        self.verified_tool_videos = {
            # === ä¸»æµèŠå¤©æœºå™¨äºº ===
            'ChatGPT': 'https://www.youtube.com/watch?v=JTxsNm9IdYU',  # OpenAIå®˜æ–¹ä»‹ç»
            'Claude': 'https://www.youtube.com/watch?v=3TDJQVo4s1c',   # Anthropicå®˜æ–¹æ¼”ç¤º
            'Bard': 'https://www.youtube.com/watch?v=yHp3jQriQpk',     # Google Bardæ¼”ç¤º
            'Gemini': 'https://www.youtube.com/watch?v=UIZAiXYceBI',   # Google Gemini
            'Character.AI': 'https://www.youtube.com/watch?v=DWuOW_v7o8Y', # Character AI
            'Perplexity': 'https://www.youtube.com/watch?v=aF4eJhcD9E8', # Perplexity AIæœç´¢
            
            # === å›¾åƒç”Ÿæˆå·¥å…· ===
            'Midjourney': 'https://www.youtube.com/watch?v=9XKNDdWWJDk', # å®˜æ–¹æ•™ç¨‹
            'DALL-E': 'https://www.youtube.com/watch?v=qTgPSKKjfVg',   # OpenAI DALL-E 2æ¼”ç¤º
            'DALL-E 2': 'https://www.youtube.com/watch?v=qTgPSKKjfVg', # OpenAI DALL-E 2æ¼”ç¤º
            'DALL-E 3': 'https://www.youtube.com/watch?v=3BBLpSj8jjY', # DALL-E 3æ¼”ç¤º
            'Stable Diffusion': 'https://www.youtube.com/watch?v=1CIpzeNxIhU', # å®˜æ–¹ä»‹ç»
            'Leonardo AI': 'https://www.youtube.com/watch?v=3dGQf2H6RN8', # Leonardo AIæ•™ç¨‹
            'Adobe Firefly': 'https://www.youtube.com/watch?v=0gNauWdOw6Q', # Adobeå®˜æ–¹
            'SeaArt': 'https://www.youtube.com/watch?v=kZZi9__p9bM',    # SeaArtæ¼”ç¤º
            'Artbreeder': 'https://www.youtube.com/watch?v=u45rP8Ilzfw', # Artbreederä»‹ç»
            
            # === è§†é¢‘ç”Ÿæˆå·¥å…· ===
            'Runway ML': 'https://www.youtube.com/watch?v=5U8bMQT8ib4',  # RunwayMLæ¼”ç¤º
            'Pika Labs': 'https://www.youtube.com/watch?v=T_0LFgJKDhA',  # Pika Labsæ¼”ç¤º
            'Synthesia': 'https://www.youtube.com/watch?v=8REp1-QO23A',  # Synthesiaæ¼”ç¤º
            'D-ID': 'https://www.youtube.com/watch?v=R6_JcGRROUo',       # D-IDè§†é¢‘ç”Ÿæˆ
            
            # === å†™ä½œåŠ©æ‰‹ ===
            'Jasper': 'https://www.youtube.com/watch?v=VYJtb2YXae8',     # Jasper AIæ¼”ç¤º
            'Copy.ai': 'https://www.youtube.com/watch?v=R7XfQvP9Sjk',    # Copy.aiæ¼”ç¤º
            'Writesonic': 'https://www.youtube.com/watch?v=q_VsNlYYlmo',  # Writesonicæ¼”ç¤º
            'Grammarly': 'https://www.youtube.com/watch?v=qQhiJyWIHTk',   # Grammarly AIåŠŸèƒ½
            'Notion AI': 'https://www.youtube.com/watch?v=57Gt1cMWCWk',  # Notionå®˜æ–¹
            'QuillBot': 'https://www.youtube.com/watch?v=t1JVzOVPn9c',   # QuillBotæ¼”ç¤º
            
            # === ä»£ç åŠ©æ‰‹ ===
            'GitHub Copilot': 'https://www.youtube.com/watch?v=DSHfHT5qnGc', # GitHubå®˜æ–¹
            'CodeWhisperer': 'https://www.youtube.com/watch?v=rQ8wYcUu-B8', # AWS CodeWhisperer
            'Tabnine': 'https://www.youtube.com/watch?v=TKLkXh_c-Gw',    # Tabnineæ¼”ç¤º
            'Codeium': 'https://www.youtube.com/watch?v=lR-0mN0JZo0',    # Codeiumæ¼”ç¤º
            
            # === æ¼”ç¤ºæ–‡ç¨¿å·¥å…· ===
            'Gamma': 'https://www.youtube.com/watch?v=7OUZ5bZb9P8',      # Gammaæ¼”ç¤º
            'Beautiful.AI': 'https://www.youtube.com/watch?v=QHSyA0V4nAE', # Beautiful.AI
            'Tome': 'https://www.youtube.com/watch?v=lzaODUqSgFc',       # Tomeæ¼”ç¤º
            
            # === è®¾è®¡å·¥å…· ===
            'Canva AI': 'https://www.youtube.com/watch?v=TGXAtGgp7as',   # Canva AIåŠŸèƒ½
            'Figma AI': 'https://www.youtube.com/watch?v=HZuk6Wkx_Eg',   # Figma AIåŠŸèƒ½
            'Framer AI': 'https://www.youtube.com/watch?v=9gJI_bQ1HQU',  # Framer AI
            
            # === éŸ³é¢‘/éŸ³ä¹å·¥å…· ===
            'ElevenLabs': 'https://www.youtube.com/watch?v=TQTlCHxyuu8',  # ElevenLabsè¯­éŸ³
            'Murf': 'https://www.youtube.com/watch?v=2O5RDBJhVzA',       # Murf AIé…éŸ³
            'AIVA': 'https://www.youtube.com/watch?v=M1eNoOTdRhE',       # AIVAéŸ³ä¹ç”Ÿæˆ
            'Suno AI': 'https://www.youtube.com/watch?v=xmQWCvGMH0Y',    # Suno AIéŸ³ä¹
            
            # === æœç´¢å¼•æ“ ===
            'Bing Chat': 'https://www.youtube.com/watch?v=SGUCcjHTmGY',  # New Bingæ¼”ç¤º
            'You.com': 'https://www.youtube.com/watch?v=JUhN8_pW-YY',    # You.com AIæœç´¢
            
            # === å…¶ä»–å·¥å…· ===
            'Luma AI': 'https://www.youtube.com/watch?v=5ysAHcJ5FKg',    # Luma AI 3Dæ‰«æ
            'Descript': 'https://www.youtube.com/watch?v=Bl_Vau09-gw',   # DescriptéŸ³é¢‘ç¼–è¾‘
            'Loom AI': 'https://www.youtube.com/watch?v=J4y50Bg0YXg',    # Loom AIåŠŸèƒ½
        }
    
    def enhance_tool_with_video(self, tool_data):
        """ä¸ºå·¥å…·æ•°æ®æ·»åŠ çœŸå®çš„æ¼”ç¤ºè§†é¢‘URL"""
        # å¦‚æœå·²æœ‰è§†é¢‘URLï¼Œè·³è¿‡
        if tool_data.get('demo_video_url'):
            return tool_data
        
        product_url = tool_data.get('product_url', '')
        product_name = tool_data.get('product_name', '')
        
        if not product_url:
            tool_data['demo_video_url'] = ''
            return tool_data
        
        logger.debug(f"ğŸ¬ æœç´¢çœŸå®è§†é¢‘: {product_name}")
        
        # ç­–ç•¥1: ä¼˜å…ˆä½¿ç”¨å·²éªŒè¯çš„çœŸå®å·¥å…·è§†é¢‘
        verified_video = self.get_verified_tool_video(product_name)
        if verified_video:
            tool_data['demo_video_url'] = verified_video
            logger.success(f"âœ… ä½¿ç”¨å·²éªŒè¯è§†é¢‘: {verified_video}")
            return tool_data
        
        # ç­–ç•¥2: æ·±åº¦æå–ç½‘ç«™çœŸå®è§†é¢‘
        real_video = self.deep_extract_real_video(product_url, product_name)
        if real_video:
            tool_data['demo_video_url'] = real_video
            logger.success(f"ğŸ¯ æå–åˆ°çœŸå®è§†é¢‘: {real_video}")
            return tool_data
        
        # ç­–ç•¥3: æœç´¢ç›¸å…³é¡µé¢çš„è§†é¢‘
        related_video = self.search_related_pages_for_video(product_url, product_name)
        if related_video:
            tool_data['demo_video_url'] = related_video
            logger.success(f"ğŸ” ä»ç›¸å…³é¡µé¢æ‰¾åˆ°è§†é¢‘: {related_video}")
            return tool_data
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œä¸ä½¿ç”¨é»˜è®¤è§†é¢‘ï¼Œä¿æŒä¸ºç©º
        tool_data['demo_video_url'] = ''
        logger.warning(f"âŒ æœªæ‰¾åˆ°çœŸå®è§†é¢‘: {product_name} - å°†å°è¯•å…¶ä»–æ–¹å¼è·å–")
        
        return tool_data
    
    def get_verified_tool_video(self, product_name):
        """è·å–å·²éªŒè¯çš„çœŸå®å·¥å…·è§†é¢‘"""
        product_lower = product_name.lower()
        
        # ç²¾ç¡®åŒ¹é…
        for tool_name, video_url in self.verified_tool_videos.items():
            if tool_name.lower() == product_lower:
                return video_url
        
        # æ¨¡ç³ŠåŒ¹é…
        for tool_name, video_url in self.verified_tool_videos.items():
            if tool_name.lower() in product_lower or product_lower in tool_name.lower():
                logger.debug(f"æ¨¡ç³ŠåŒ¹é…åˆ°å·²éªŒè¯è§†é¢‘: {tool_name}")
                return video_url
        
        return None
    
    def deep_extract_real_video(self, url, tool_name):
        """æ·±åº¦æå–ç½‘ç«™çš„çœŸå®æ¼”ç¤ºè§†é¢‘"""
        try:
            # æ ‡å‡†åŒ–URL
            if not url.startswith(('http://', 'https://')):
                url = 'https://' + url
            
            logger.debug(f"ğŸ” æ·±åº¦åˆ†æç½‘ç«™: {url}")
            
            # è·å–ç½‘é¡µå†…å®¹
            response = self.session.get(url, timeout=self.timeout)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # æ–¹æ³•1: æŸ¥æ‰¾é«˜ä¼˜å…ˆçº§çš„è§†é¢‘å…ƒç´ 
            video_url = self.find_priority_videos(soup, url)
            if video_url:
                return video_url
            
            # æ–¹æ³•2: åˆ†æJSON-LDç»“æ„åŒ–æ•°æ®ä¸­çš„è§†é¢‘
            video_url = self.extract_video_from_jsonld(soup)
            if video_url:
                return video_url
            
            # æ–¹æ³•3: æŸ¥æ‰¾å¸¦æœ‰æ¼”ç¤º/ä»‹ç»å…³é”®è¯çš„è§†é¢‘
            video_url = self.find_demo_videos_by_context(soup, url)
            if video_url:
                return video_url
            
            # æ–¹æ³•4: æ£€æŸ¥ç‰¹å®šçš„è§†é¢‘é¡µé¢è·¯å¾„
            video_url = self.check_common_video_paths(url)
            if video_url:
                return video_url
            
            return None
            
        except Exception as e:
            logger.debug(f"æ·±åº¦è§†é¢‘æå–å¤±è´¥ {url}: {e}")
            return None
    
    def find_priority_videos(self, soup, base_url):
        """æŸ¥æ‰¾é«˜ä¼˜å…ˆçº§çš„è§†é¢‘å…ƒç´ """
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºæŸ¥æ‰¾è§†é¢‘
        priority_selectors = [
            # é¦–é¡µè‹±é›„åŒºåŸŸçš„è§†é¢‘
            '.hero video, .hero iframe',
            '.banner video, .banner iframe',
            '.intro video, .intro iframe',
            
            # äº§å“æ¼”ç¤ºåŒºåŸŸ
            '.demo video, .demo iframe',
            '.product-demo video, .product-demo iframe',
            '.showcase video, .showcase iframe',
            
            # æ ‡è®°ä¸ºä¸»è¦è§†é¢‘çš„å…ƒç´ 
            '.main-video, .primary-video, .featured-video',
            '[data-main-video], [data-featured-video]',
            
            # YouTube/VimeoåµŒå…¥
            'iframe[src*="youtube.com/embed"]',
            'iframe[src*="vimeo.com/video"]',
            'iframe[src*="loom.com/embed"]',
        ]
        
        for selector in priority_selectors:
            elements = soup.select(selector)
            for element in elements:
                video_url = self.extract_video_url_from_element(element, base_url)
                if video_url:
                    logger.debug(f"é«˜ä¼˜å…ˆçº§è§†é¢‘å…ƒç´ æ‰¾åˆ°: {selector}")
                    return video_url
        
        return None
    
    def extract_video_from_jsonld(self, soup):
        """ä»JSON-LDç»“æ„åŒ–æ•°æ®æå–è§†é¢‘"""
        try:
            scripts = soup.find_all('script', type='application/ld+json')
            for script in scripts:
                if script.string:
                    import json
                    data = json.loads(script.string)
                    
                    # é€’å½’æŸ¥æ‰¾è§†é¢‘URL
                    video_url = self.find_video_in_jsonld(data)
                    if video_url:
                        return video_url
        except Exception as e:
            logger.debug(f"JSON-LDè§†é¢‘æå–å¤±è´¥: {e}")
        
        return None
    
    def find_video_in_jsonld(self, data):
        """åœ¨JSON-LDæ•°æ®ä¸­é€’å½’æŸ¥æ‰¾è§†é¢‘"""
        if isinstance(data, dict):
            # æ£€æŸ¥å¸¸è§çš„è§†é¢‘å­—æ®µ
            video_fields = ['video', 'embedUrl', 'contentUrl', 'url']
            for field in video_fields:
                if field in data and isinstance(data[field], str):
                    if self.is_video_url(data[field]):
                        return self.normalize_video_url(data[field])
            
            # é€’å½’æ£€æŸ¥åµŒå¥—å¯¹è±¡
            for value in data.values():
                result = self.find_video_in_jsonld(value)
                if result:
                    return result
        
        elif isinstance(data, list):
            for item in data:
                result = self.find_video_in_jsonld(item)
                if result:
                    return result
        
        return None
    
    def find_demo_videos_by_context(self, soup, base_url):
        """é€šè¿‡ä¸Šä¸‹æ–‡å…³é”®è¯æŸ¥æ‰¾æ¼”ç¤ºè§†é¢‘"""
        # æŸ¥æ‰¾åŒ…å«æ¼”ç¤ºå…³é”®è¯çš„åŒºåŸŸ
        for keyword in self.video_keywords:
            # æŸ¥æ‰¾æ ‡é¢˜æˆ–æ–‡æœ¬åŒ…å«å…³é”®è¯çš„å®¹å™¨
            containers = soup.find_all(text=re.compile(keyword, re.IGNORECASE))
            
            for text_node in containers:
                # å‘ä¸ŠæŸ¥æ‰¾åŒ…å«è¯¥æ–‡æœ¬çš„å®¹å™¨å…ƒç´ 
                container = text_node.parent
                for _ in range(3):  # æœ€å¤šå‘ä¸ŠæŸ¥æ‰¾3å±‚
                    if container:
                        # åœ¨å®¹å™¨ä¸­æŸ¥æ‰¾è§†é¢‘
                        video_elements = container.find_all(['iframe', 'video', 'embed'])
                        for element in video_elements:
                            video_url = self.extract_video_url_from_element(element, base_url)
                            if video_url:
                                logger.debug(f"é€šè¿‡å…³é”®è¯'{keyword}'æ‰¾åˆ°è§†é¢‘")
                                return video_url
                        container = container.parent
                    else:
                        break
        
        return None
    
    def check_common_video_paths(self, base_url):
        """æ£€æŸ¥å¸¸è§çš„è§†é¢‘é¡µé¢è·¯å¾„"""
        parsed = urlparse(base_url)
        common_paths = [
            '/demo', '/demo/', '/demos', '/demos/',
            '/video', '/video/', '/videos', '/videos/',
            '/tutorial', '/tutorial/', '/tutorials', '/tutorials/',
            '/overview', '/overview/', '/introduction', '/introduction/',
            '/getting-started', '/how-it-works', '/product-tour'
        ]
        
        for path in common_paths:
            try:
                video_page_url = f"{parsed.scheme}://{parsed.netloc}{path}"
                logger.debug(f"æ£€æŸ¥è§†é¢‘é¡µé¢: {video_page_url}")
                
                response = self.session.get(video_page_url, timeout=10)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.content, 'html.parser')
                    
                    # åœ¨è¿™äº›é¡µé¢ä¸­æŸ¥æ‰¾è§†é¢‘
                    video_elements = soup.find_all(['iframe', 'video'])
                    for element in video_elements:
                        video_url = self.extract_video_url_from_element(element, video_page_url)
                        if video_url:
                            logger.debug(f"åœ¨è·¯å¾„{path}æ‰¾åˆ°è§†é¢‘")
                            return video_url
                
                # é¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                time.sleep(1)
                
            except Exception:
                continue
        
        return None
    
    def search_related_pages_for_video(self, base_url, tool_name):
        """æœç´¢ç›¸å…³é¡µé¢çš„è§†é¢‘"""
        try:
            parsed = urlparse(base_url)
            
            # å°è¯•ä»sitemapæ‰¾åˆ°è§†é¢‘é¡µé¢
            sitemap_urls = [
                f"{parsed.scheme}://{parsed.netloc}/sitemap.xml",
                f"{parsed.scheme}://{parsed.netloc}/sitemap_index.xml",
                f"{parsed.scheme}://{parsed.netloc}/robots.txt"
            ]
            
            for sitemap_url in sitemap_urls:
                try:
                    response = self.session.get(sitemap_url, timeout=10)
                    if response.status_code == 200:
                        # æŸ¥æ‰¾å¯èƒ½åŒ…å«è§†é¢‘çš„é¡µé¢URL
                        video_page_urls = re.findall(
                            r'https?://[^\s<>"]+(?:demo|video|tutorial|overview|introduction)[^\s<>"]*',
                            response.text,
                            re.IGNORECASE
                        )
                        
                        for url in video_page_urls[:3]:  # é™åˆ¶æ£€æŸ¥æ•°é‡
                            video_url = self.extract_video_from_page(url)
                            if video_url:
                                return video_url
                        
                        break  # æ‰¾åˆ°sitemapå°±ä¸ç»§ç»­äº†
                except Exception:
                    continue
            
        except Exception as e:
            logger.debug(f"æœç´¢ç›¸å…³é¡µé¢å¤±è´¥: {e}")
        
        return None
    
    def extract_video_from_page(self, url):
        """ä»æŒ‡å®šé¡µé¢æå–è§†é¢‘"""
        try:
            response = self.session.get(url, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # æŸ¥æ‰¾è§†é¢‘å…ƒç´ 
                video_elements = soup.find_all(['iframe', 'video'])
                for element in video_elements:
                    video_url = self.extract_video_url_from_element(element, url)
                    if video_url:
                        return video_url
        except Exception:
            pass
        
        return None
    
    def extract_video_url_from_element(self, element, base_url):
        """ä»HTMLå…ƒç´ æå–è§†é¢‘URL"""
        if element.name == 'iframe':
            src = element.get('src', '')
            if src:
                full_url = urljoin(base_url, src)
                if self.is_video_url(full_url):
                    return self.normalize_video_url(full_url)
        
        elif element.name == 'video':
            # æ£€æŸ¥videoå…ƒç´ çš„srcå±æ€§
            src = element.get('src', '')
            if src:
                full_url = urljoin(base_url, src)
                return full_url
            
            # æ£€æŸ¥sourceå­å…ƒç´ 
            sources = element.find_all('source')
            for source in sources:
                src = source.get('src', '')
                if src:
                    full_url = urljoin(base_url, src)
                    return full_url
        
        elif element.name == 'embed':
            src = element.get('src', '')
            if src:
                full_url = urljoin(base_url, src)
                if self.is_video_url(full_url):
                    return self.normalize_video_url(full_url)
        
        return None
    
    def is_video_url(self, url):
        """æ£€æŸ¥URLæ˜¯å¦ä¸ºè§†é¢‘URL"""
        if not url:
            return False
        
        # æ£€æŸ¥å„ç§è§†é¢‘å¹³å°
        for platform, pattern in self.video_patterns.items():
            if re.search(pattern, url, re.IGNORECASE):
                return True
        
        return False
    
    def normalize_video_url(self, url):
        """æ ‡å‡†åŒ–è§†é¢‘URLä¸ºå¯åµŒå…¥çš„æ ¼å¼"""
        if not url:
            return ""
        
        # YouTube URLæ ‡å‡†åŒ– - è½¬æ¢ä¸ºwatchæ ¼å¼ä¾¿äºå‰ç«¯å¤„ç†
        youtube_match = re.search(self.video_patterns['youtube'], url)
        if youtube_match:
            video_id = youtube_match.group(1)
            return f"https://www.youtube.com/watch?v={video_id}"
        
        # Vimeo URLæ ‡å‡†åŒ–
        vimeo_match = re.search(self.video_patterns['vimeo'], url)
        if vimeo_match:
            video_id = vimeo_match.group(1)
            return f"https://vimeo.com/{video_id}"
        
        # Loom URLæ ‡å‡†åŒ–
        loom_match = re.search(self.video_patterns['loom'], url)
        if loom_match:
            video_id = loom_match.group(1)
            return f"https://www.loom.com/share/{video_id}"
        
        # å…¶ä»–å¹³å°ä¿æŒåŸæ ·
        return url
    
    def validate_video_url(self, url):
        """éªŒè¯è§†é¢‘URLæ˜¯å¦æœ‰æ•ˆä¸”å¯è®¿é—®"""
        if not url:
            return False
        
        try:
            # å¯¹äºYouTubeè§†é¢‘ï¼Œæ£€æŸ¥video IDçš„æœ‰æ•ˆæ€§
            if 'youtube.com' in url or 'youtu.be' in url:
                response = self.session.head(url, timeout=10)
                return response.status_code == 200
            
            # å¯¹äºå…¶ä»–è§†é¢‘ï¼Œç®€å•æ£€æŸ¥HTTPçŠ¶æ€
            response = self.session.head(url, timeout=10)
            return response.status_code == 200
            
        except Exception:
            return False

# å…¨å±€å®ä¾‹
video_helper = VideoHelper() 